ggplot(aes(x = nominate_dim1, y = nominate_dim2,  color = party)) +
geom_text(aes(label = state_abbrev),alpha  = .5, size = 2) +
facet_wrap(~ congress, ncol = 2) + #show terms seperately
scale_color_manual(values = c("blue", "red")) +
guides(color = FALSE) +  theme_minimal()
library(tidyverse)
moc <- read_csv("https://www.dropbox.com/s/zof46j8amci71ps/house_members.csv?dl=1")
filter(moc, congress  %in% c(116)) %>% #Select two terms
#sample_frac(.4) %>%
ggplot(aes(x = nominate_dim1, y = nominate_dim2,  color = party)) +
geom_text(aes(label = state_abbrev),alpha  = .5, size = 2) +
facet_wrap(~ congress, ncol = 2) + #show terms seperately
scale_color_manual(values = c("blue", "red")) +
guides(color = FALSE) +  theme_minimal()
filter(moc, congress  %in% c(116)) %>% #Select two terms
mutate(moc, squad = ifelse(icpsr %in% c(21955, 21949, 21950, 21975)))
ggplot(aes(x = nominate_dim1, y = nominate_dim2,  color = party)) +
geom_text(aes(label = squad),alpha  = .5, size = 2) +
scale_color_manual(values = c("blue", "red")) +
guides(color = FALSE) +  theme_minimal()
filter(moc, congress  %in% c(116)) %>% #Select two terms
mutate(moc, squad = ifelse(icpsr %in% c(21955, 21949, 21950, 21975))) %>%
ggplot(aes(x = nominate_dim1, y = nominate_dim2,  color = party)) +
geom_text(aes(label = squad),alpha  = .5, size = 2) +
scale_color_manual(values = c("blue", "red")) +
guides(color = FALSE) +  theme_minimal()
filter(moc, congress  %in% c(116)) %>% #Select two terms
mutate(squad = ifelse(icpsr %in% c(21955, 21949, 21950, 21975))) %>%
ggplot(aes(x = nominate_dim1, y = nominate_dim2,  color = party)) +
geom_text(aes(label = squad),alpha  = .5, size = 2) +
scale_color_manual(values = c("blue", "red")) +
guides(color = FALSE) +  theme_minimal()
filter(moc, congress  %in% c(116)) %>% #Select two terms
mutate(squad = ifelse(icpsr %in% c(21955, 21949, 21950, 21975), "Squad", "Not Squat")) %>%
ggplot(aes(x = nominate_dim1, y = nominate_dim2,  color = party)) +
geom_text(aes(label = squad),alpha  = .5, size = 2) +
scale_color_manual(values = c("blue", "red")) +
guides(color = FALSE) +  theme_minimal()
input <- "Town1,Town2,Town3,Town4,Town5,NYC
70,95,34,46,10,50
65,88,45,24,32,51
87,91,23,35,10,78
67,101,34,55,15,88"
print(df)
# Q1. Find which location has biggest standard deviation.
q1 <- names(which.max(apply(df, 2, sd)))
# Q2.  Find median NYC temperature when town 2 has temp between 90 and 100 inclusive.
q2_tmp <- df %>% filter(Town2 >= 90 & Town2 <= 100) %>% select("NYC")
q2 <- toString(round(median(q2_tmp$NYC)))
# Split into training and test
NYC <- df$NYC
df <- df %>% select(-NYC)
# Q3 + Q4
abs_beta_sum <- 0
lowest_MSE_so_far <- Inf
most_predictive_town <- ""
# Iterate over towns, regressing NYC on each town.
# Calculate sum of absolute values of slopes, and find most predictive town.
for (column_i in 1:(ncol(df)-1)) {
lm_res <- lm(NYC ~ df[,column_i])
abs_beta_sum = abs_beta_sum + abs(lm_res$coefficients[2])
mse <- mean(lm_res$residuals**2)
# Update best MSE if necessary
if (mse < lowest_MSE_so_far) {
lowest_MSE_so_far <- mse
most_predictive_town <- names(df)[column_i]
}
}
q3 <- toString(round(abs_beta_sum))
q4 <- most_predictive_town
# Q5
lowest_MSE_so_far <- Inf
most_predictive_town_combo <- ""
# Iterate over pairs of towns, regressing NYC on each pair of towns
# to find most predictive pair
for (column_i in 1:(ncol(df)-1)) {
for (column_j in column_i:(ncol(df)-1)) {
lm_res <- lm(NYC ~ df[,column_i] + df[,column_j])
mse <- mean(lm_res$residuals**2)
# Update best MSE if necessary
if (mse < lowest_MSE_so_far) {
lowest_MSE_so_far <- mse
most_predictive_town_combo <- paste(names(df)[column_i], names(df)[column_j], sep=",")
}
}
}
q5 <- most_predictive_town_combo
ans <- paste(q1, q2, q3, q4, q5, sep=",")
# Q1. Find which location has biggest standard deviation.
q1 <- names(which.max(apply(df, 2, sd)))
library(dplyr)
# Q1. Find which location has biggest standard deviation.
q1 <- names(which.max(apply(df, 2, sd)))
df
df <- read.table(text = input,
header = TRUE,
sep = ",")
print(df)
# Q1. Find which location has biggest standard deviation.
q1 <- names(which.max(apply(df, 2, sd)))
q2_tmp <- df %>% filter(Town2 >= 90 & Town2 <= 100) %>% select("NYC")
q2 <- toString(round(median(q2_tmp$NYC)))
# Split into training and test
NYC <- df$NYC
df <- df %>% select(-NYC)
abs_beta_sum <- 0
lowest_MSE_so_far <- Inf
most_predictive_town <- ""
# Iterate over towns, regressing NYC on each town.
# Calculate sum of absolute values of slopes, and find most predictive town.
for (column_i in 1:(ncol(df)-1)) {
lm_res <- lm(NYC ~ df[,column_i])
abs_beta_sum = abs_beta_sum + abs(lm_res$coefficients[2])
mse <- mean(lm_res$residuals**2)
# Update best MSE if necessary
if (mse < lowest_MSE_so_far) {
lowest_MSE_so_far <- mse
most_predictive_town <- names(df)[column_i]
}
}
q3 <- toString(round(abs_beta_sum))
q4 <- most_predictive_town
# Q5
lowest_MSE_so_far <- Inf
most_predictive_town_combo <- ""
# Iterate over pairs of towns, regressing NYC on each pair of towns
# to find most predictive pair
for (column_i in 1:(ncol(df)-1)) {
for (column_j in column_i:(ncol(df)-1)) {
lm_res <- lm(NYC ~ df[,column_i] + df[,column_j])
mse <- mean(lm_res$residuals**2)
# Update best MSE if necessary
if (mse < lowest_MSE_so_far) {
lowest_MSE_so_far <- mse
most_predictive_town_combo <- paste(names(df)[column_i], names(df)[column_j], sep=",")
}
}
}
q5 <- most_predictive_town_combo
ans <- paste(q1, q2, q3, q4, q5, sep=",")
lm(NYC ~ df)
df
lm(NYC ~ df[,:])
lm(NYC ~ as.matrix(df[,:]))
lm(NYC ~ as.matrix(df))
as.matrix(df)
lm(NYC ~ as.matrix(df))
NYC
as.matrix(df)
lm(NYC ~ T(as.matrix(df)))
lm(NYC ~ t(as.matrix(df)))
lm(NYC ~ ., data= df)
NYC
df
class(df)
lm(NYC ~ ., data= df)
df
NYC ~ .
NYC ~ df
lm(NYC ~ df)
lm(NYC ~ as.matrix(df))
lm(NYC ~ ., data= df)
summary(res)
res <- lm(NYC ~ ., data= df)
summary(res)
res$coefficients
lm_sum <- summary(res)
lm_sum$coefficients
lm_sum$coefficients[,1]
res$coefficients/(lm_sum$coefficients[,1])
lm_sum$coefficients
sort(c(3, 1, 2))
?knn
?knn
df <- read.csv("../../data/debate_transcripts_by_candidate_ordered_v1.csv")
df$debate_date <- mdy(df$debate_date)
library(tidyverse)
library(syuzhet)
library(lubridate)
# Group by debate date
df_by_debate <- df %>% group_by(debate_date) %>% summarise_all(paste, collapse = ' ')
sentiment_plotting_func <- function(df) {
df_by_debate['syuzhet_sentiment'] <- get_sentiment(df_by_debate$text, method="syuzhet")
ggplot(df_by_debate, aes(x=df_by_debate$debate_date, y=df_by_debate$syuzhet_sentiment)) +
geom_line()
}
sentiment_plotting_func(df_by_debate)
df <- read.csv("../../data/debate_transcripts_by_candidate_ordered_v1.csv")
df$debate_date <- mdy(df$debate_date)
library(tidyverse)
library(syuzhet)
library(lubridate)
# Group by debate date
df_by_debate <- df %>% group_by(debate_date) %>% summarise_all(paste, collapse = ' ')
df_by_debate['syuzhet_sentiment'] <- get_sentiment(df_by_debate$text, method="syuzhet")
ggplot(df_by_debate, aes(x=df_by_debate$debate_date, y=df_by_debate$syuzhet_sentiment)) +
geom_line()
# Group by debate date
df_by_debate <- df %>% group_by(debate_date) %>% summarise_all(paste, collapse = ' ')
df <- read.csv("../../data/debate_transcripts_by_candidate_ordered_v1.csv")
df$debate_date <- mdy(df$debate_date)
# ref: https://javewa.github.io/2018/08/14/trolls/
library(tidyverse)
library(syuzhet)
library(lubridate)
df <- read.csv("../../data/debate_transcripts_by_candidate_ordered_v1.csv")
df$debate_date <- mdy(df$debate_date)
# ref: https://javewa.github.io/2018/08/14/trolls/
library(tidyverse)
library(syuzhet)
library(lubridate)
df <- read.csv("../../data/debate_transcripts_by_candidate_ordered_v1.csv")
setwd("~/Spring20/17835/17835-final-project/scripts/NLP")
df <- read.csv("../../data/debate_transcripts_by_candidate_ordered_v1.csv")
df$debate_date <- mdy(df$debate_date)
# Group by debate date
df_by_debate <- df %>% group_by(debate_date) %>% summarise_all(paste, collapse = ' ')
df_by_debate['syuzhet_sentiment'] <- get_sentiment(df_by_debate$text, method="syuzhet")
ggplot(df_by_debate, aes(x=df_by_debate$debate_date, y=df_by_debate$syuzhet_sentiment)) +
geom_line()
View(df_by_debate)
df_by_debate_after1999 <- df_by_debate %>% filter(election_cycle >= 2000)
ggplot(df_by_debate_after1999, aes(x=debate_date, y=syuzhet_sentiment)) +
geom_line()
df_by_cycle <- df %>% group_by(election_cycle) %>% summarise_all(paste, collapse = ' ')
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="syuzhet")
ggplot(df_by_cycle, aes(x=debate_date, y=syuzhet_sentiment)) +
geom_line()
View(df_by_cycle)
head(df_by_cycle)
##########################################3
# Group by debate date
df_by_debate <- df %>% group_by(debate_date) %>% summarise(text = paste0(text))
##########################################3
# Group by debate date
df_by_debate <- df %>% group_by(debate_date) %>% summarise(text = paste0(text, collapse=""))
View(df_by_debate)
View(df_by_debate)
df_by_debate <- df %>% group_by(debate_date) %>% summarise(text = paste0(text, collapse=""))
df_by_debate['syuzhet_sentiment'] <- get_sentiment(df_by_debate$text, method="syuzhet")
ggplot(df_by_debate, aes(x=df_by_debate$debate_date, y=df_by_debate$syuzhet_sentiment)) +
geom_line()
df_by_debate_after1999 <- df_by_debate %>% filter(election_cycle >= 2000)
ggplot(df_by_debate_after1999, aes(x=debate_date, y=syuzhet_sentiment)) +
geom_line()
df_by_cycle <- df %>% group_by(election_cycle) %>% summarise_all(paste, collapse = ' ')
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="syuzhet")
ggplot(df_by_cycle, aes(x=debate_date, y=syuzhet_sentiment)) +
geom_line()
df_by_cycle <- df %>% group_by(election_cycle) %>%  summarise(text = paste0(text, collapse=""))
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="syuzhet")
ggplot(df_by_cycle, aes(x=debate_date, y=syuzhet_sentiment)) +
geom_line()
ggplot(df_by_cycle, aes(x=election_cycle, y=syuzhet_sentiment)) +
geom_line()
ggplot(df_by_debate_after1999, aes(x=debate_date, y=syuzhet_sentiment)) +
geom_line()
ggplot(df_by_cycle, aes(x=election_cycle, y=syuzhet_sentiment)) +
geom_line()
?get_sentiment
df_by_cycle <- df %>% group_by(election_cycle) %>%  summarise(text = paste0(text, collapse=""))
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="bing")
ggplot(df_by_cycle, aes(x=election_cycle, y=syuzhet_sentiment)) +
geom_line()
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="stanford")
ggplot(df_by_cycle, aes(x=election_cycle, y=syuzhet_sentiment)) +
geom_line()
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="stanford")
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="bing")
ggplot(df_by_cycle, aes(x=election_cycle, y=syuzhet_sentiment)) +
geom_line()
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="afinn")
ggplot(df_by_cycle, aes(x=election_cycle, y=syuzhet_sentiment)) +
geom_line()
library(tidyverse)
library(syuzhet)
library(lubridate)
df <- read.csv("../../data/debate_transcripts_by_candidate_ordered_v1.csv")
df$debate_date <- mdy(df$debate_date)
##########################################3
# Group by debate date
df_by_debate <- df %>% group_by(debate_date) %>% summarise(text = paste0(text, collapse=""))
df_by_debate['syuzhet_sentiment'] <- get_sentiment(df_by_debate$text, method="syuzhet")
ggplot(df_by_debate, aes(x=df_by_debate$debate_date, y=df_by_debate$syuzhet_sentiment)) +
geom_line()
df_by_debate_after1999 <- df_by_debate %>% filter(election_cycle >= 2000)
ggplot(df_by_debate_after1999, aes(x=debate_date, y=syuzhet_sentiment)) +
geom_line()
##########################################
# Group by election cycle
df_by_cycle <- df %>% group_by(election_cycle) %>%  summarise(text = paste0(text, collapse=""))
df_by_cycle['syuzhet_sentiment'] <- get_sentiment(df_by_cycle$text, method="afinn")
ggplot(df_by_cycle, aes(x=election_cycle, y=syuzhet_sentiment)) +
geom_line()
head(df)
colnames(df)
library(quanteda)
library(readtext)
?corpus
corpus(df_by_debate, docnames = debate_date, docvars=text)
corpus(df_by_debate, docnames = "debate_date", docvars="text")
corpus(df_by_debate, docid_field = "debate_date", text_field="text")
corpus_id <- corpus(df_by_debate, docid_field = "debate_date", text_field="text")
by_debate_corpus <- corpus(df_by_debate, docid_field = "debate_date", text_field="text")
by_debate_corpus <- corpus(df_by_debate, docid_field = "debate_date", text_field="text")
by_debate_dfm <- dfm(by_debate_corpus, remove = stopwords("english"), remove_numbers = TRUE, remove_punct = TRUE, stem = TRUE)
textplot_wordcloud(dfm["1960-09-26", ], max_words = 20) # essay No. 12
library(RColorBrewer)
textplot_wordcloud(dfm["1960-09-26", ], max_words = 20) # essay No. 12
dfm["1960-09-26", ]
dfm["1960-09-26"]
dfm["1960-09-26",]
textplot_wordcloud(by_debate_dfm["1960-09-26", ], max_words = 20) # essay No. 12
textplot_wordcloud(by_debate_dfm["fp24.txt", ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
textplot_wordcloud(by_debate_dfm["1960-09-26", ], max_words = 20) # essay No. 12
for (date in df_by_debate$debate_date[1:5]) {
textplot_wordcloud(by_debate_dfm[date, ], max_words = 20) # essay No. 12
}
df_by_debate$debate_date[1:5]
for (date in df_by_debate$debate_date[1:5]) {
print(date)}
for (date in df_by_debate$debate_date[1:5]) {
print(str(date))}
df_by_debate$debate_date[1:5]
for (date in df_by_debate$debate_date[1:5]) {
print(str(date))}
for (date in df_by_debate$debate_date[1:5]) {
print(date)}
df_by_debate$debate_date[1:5]
df_by_debate$debate_date[1:5] + 1
type(df_by_debate$debate_date[1:5])
class(df_by_debate$debate_date[1:5])
for (date in df_by_debate$debate_date) {
print(toString(date))}
df_by_debate$debate_date[0]
df_by_debate$debate_date[1]
print(df_by_debate$debate_date[1])
x <- df_by_debate$debate_date[1]
x
x.format
x.format()
x
format(x)
for (date in df_by_debate$debate_date) {
print(toString(format(date)))
}
for (date in df_by_debate$debate_date) {
print(format(date))
}
df$debate_date
df$debate_date[0]
df$debate_date[1]
df <- read.csv("../../data/debate_transcripts_by_candidate_ordered_v1.csv")
df$debate_date
print(df$debate_date)
date
df_by_debate$debate_date[1]
x <- df_by_debate$debate_date[1]
x
print(x)
x
toString(x)
for (x in df_by_debate$debate_date) {
print(x)
}
df_by_debate$debate_date
for (x in as.character(df_by_debate$debate_date)) {
print(x)
}
for (x in as.character(df_by_debate$debate_date)) {
print(x)
}
for (doc_name in as.character(df_by_debate$debate_date)) {
textplot_wordcloud(by_debate_dfm[doc_name, ], max_words = 20) # essay No. 12
}
for (doc_name in as.character(df_by_debate$debate_date)[1:20]) {
textplot_wordcloud(by_debate_dfm[doc_name, ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
}
?textplot_wordcloud
paste0('hi', "my", "name")
getwd()
library(RColorBrewer)
for (doc_name in as.character(df_by_debate$debate_date)) {
png(filename=paste0("../../plots/wordplots/by_debate/", doc_name, "_wordplot.png"))
textplot_wordcloud(by_debate_dfm[doc_name, ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
dev.off()
}
dir.create(file.path("../../plots/wordplots/by_debate/"), showWarnings = FALSE)
for (doc_name in as.character(df_by_debate$debate_date)) {
png(filename=paste0("../../plots/wordplots/by_debate/", doc_name, "_wordplot.png"))
textplot_wordcloud(by_debate_dfm[doc_name, ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
dev.off()
}
dir.create(file.path("../../plots/word_clouds/by_debate/"), showWarnings = FALSE)
for (doc_name in as.character(df_by_debate$debate_date)) {
png(filename=paste0("../../plots/word_clouds/by_debate/", doc_name, "_wordplot.png"))
textplot_wordcloud(by_debate_dfm[doc_name, ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
dev.off()
}
by_cycle_corpus <- corpus(df_by_cycle, docid_field = "election_cycle", text_field="text")
by_cycle_dfm <- dfm(by_cycle_corpus, remove = stopwords("english"), remove_numbers = TRUE, remove_punct = TRUE, stem = TRUE)
dir.create(file.path("../../plots/word_clouds/by_election_cycle/"), showWarnings = FALSE)
for (doc_name in as.character(df_by_cycle$election_cycle)) {
png(filename=paste0("../../plots/word_clouds/by_election_cycle/", doc_name, "_word_cloud.png"))
textplot_wordcloud(by_debate_dfm[doc_name, ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
dev.off()
}
as.character(df_by_cycle$election_cycle)
for (doc_name in as.character(df_by_cycle$election_cycle)) {
png(filename=paste0("../../plots/word_clouds/by_election_cycle/", doc_name, "_word_cloud.png"))
textplot_wordcloud(by_debate_dfm[doc_name, ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
dev.off()
}
by_cycle_dfm <- dfm(by_cycle_corpus, remove = stopwords("english"), remove_numbers = TRUE, remove_punct = TRUE, stem = TRUE)
dir.create(file.path("../../plots/word_clouds/by_election_cycle/"), showWarnings = FALSE)
for (doc_name in as.character(df_by_cycle$election_cycle)) {
png(filename=paste0("../../plots/word_clouds/by_election_cycle/", doc_name, "_word_cloud.png"))
textplot_wordcloud(by_cycle_dfm[doc_name, ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
dev.off()
}
by_cycle_dfm_tfidf <- dfm_tfidf(by_cycle_dfm, base = 2)
View(by_cycle_dfm_tfidf)
k <- 4 # number of clusters
# ## subset The Federalist papers written by Hamilton
# hamilton <- c(1, 6:9, 11:13, 15:17, 21:36, 59:61, 65:85)
# dfm.tfidf.hamilton <- dfm_tfidf[hamilton,]
## run k-means
km.out <- stats::kmeans(by_cycle_dfm_tfidf, centers = k)
## label each centroid with the corresponding term
# colnames(km.out$centers) <- featnames(dfm.tfidf.hamilton)
for (i in 1:k) { # loop for each cluster
cat("CLUSTER", i)
cat("Top 10 words:") # 10 most important terms at the centroid
print(head(sort(km.out$centers[i, ], decreasing = TRUE), n = 10))
cat("Federalist Papers classified: ") # extract essays classified
print(docnames(dfm.tfidf.hamilton)[km.out$cluster == i])
}
km.out <- stats::kmeans(by_cycle_dfm_tfidf, centers = k)
## label each centroid with the corresponding term
# colnames(km.out$centers) <- featnames(dfm.tfidf.hamilton)
for (i in 1:k) { # loop for each cluster
cat("CLUSTER", i)
cat("Top 10 words:") # 10 most important terms at the centroid
print(head(sort(km.out$centers[i, ], decreasing = TRUE), n = 10))
cat("Federalist Papers classified: ") # extract essays classified
print(docnames(by_cycle_dfm_tfidf)[km.out$cluster == i])
}
k <- 2 # number of clusters
# ## subset The Federalist papers written by Hamilton
# hamilton <- c(1, 6:9, 11:13, 15:17, 21:36, 59:61, 65:85)
# dfm.tfidf.hamilton <- dfm_tfidf[hamilton,]
## run k-means
km.out <- stats::kmeans(by_cycle_dfm_tfidf, centers = k)
## label each centroid with the corresponding term
# colnames(km.out$centers) <- featnames(dfm.tfidf.hamilton)
for (i in 1:k) { # loop for each cluster
cat("CLUSTER", i)
cat("Top 10 words:") # 10 most important terms at the centroid
print(head(sort(km.out$centers[i, ], decreasing = TRUE), n = 10))
cat("Federalist Papers classified: ") # extract essays classified
print(docnames(by_cycle_dfm_tfidf)[km.out$cluster == i])
}
for (i in 1:k) { # loop for each cluster
cat("CLUSTER", i)
cat("Top 10 words:") # 10 most important terms at the centroid
print(head(sort(km.out$centers[i, ], decreasing = TRUE), n = 10))
cat("Years classified: ")
print(docnames(by_cycle_dfm_tfidf)[km.out$cluster == i])
}
by_debate_dfm_tfidf <- dfm_tfidf(by_debate_dfm, base = 2)
k <- 2 # number of clusters
# subset The Federalist papers written by Hamilton
# hamilton <- c(1, 6:9, 11:13, 15:17, 21:36, 59:61, 65:85)
# dfm.tfidf.hamilton <- dfm_tfidf[hamilton,]
## run k-means
km.out <- stats::kmeans(by_debate_dfm_tfidf, centers = k)
## label each centroid with the corresponding term
# colnames(km.out$centers) <- featnames(dfm.tfidf.hamilton)
for (i in 1:k) { # loop for each cluster
cat("CLUSTER", i)
cat("Top 10 words:") # 10 most important terms at the centroid
print(head(sort(km.out$centers[i, ], decreasing = TRUE), n = 10))
cat("Years classified: ")
print(docnames(by_debate_dfm_tfidf)[km.out$cluster == i])
}
by_debate_dfm_tfidf <- dfm_tfidf(by_debate_dfm, base = 2)
k <- 4 # number of clusters
# subset The Federalist papers written by Hamilton
# hamilton <- c(1, 6:9, 11:13, 15:17, 21:36, 59:61, 65:85)
# dfm.tfidf.hamilton <- dfm_tfidf[hamilton,]
## run k-means
km.out <- stats::kmeans(by_debate_dfm_tfidf, centers = k)
## label each centroid with the corresponding term
# colnames(km.out$centers) <- featnames(dfm.tfidf.hamilton)
for (i in 1:k) { # loop for each cluster
cat("CLUSTER", i)
cat("Top 10 words:") # 10 most important terms at the centroid
print(head(sort(km.out$centers[i, ], decreasing = TRUE), n = 10))
cat("Years classified: ")
print(docnames(by_debate_dfm_tfidf)[km.out$cluster == i])
}
clear()
clear
by_debate_corpus <- corpus(df_by_debate, docid_field = "debate_date", text_field="text")
by_debate_dfm <- dfm(by_debate_corpus, remove = stopwords("english"), remove_numbers = TRUE, remove_punct = TRUE, stem = TRUE)
dir.create(file.path("../../plots/word_clouds/by_debate/"), showWarnings = FALSE)
for (doc_name in as.character(df_by_debate$debate_date)) {
png(filename=paste0("../../plots/word_clouds/by_debate/", doc_name, "_word_cloud.png"))
textplot_wordcloud(by_debate_dfm[doc_name, ], max_words = 100, color = rev(RColorBrewer::brewer.pal(10, "RdBu")))
dev.off()
}
git add .
